{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:blue'> ***NAIVE BAYES***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores a Naive Bayes approach to toxicity classification. The goal here is to identify toxic content in text.  \n",
    "We'll preprocess the data and evaluate the performance of Naive Bayes as a baseline classifier for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "import html\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxicity/train.csv',usecols=['comment_text','malignant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset with balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = df[df['malignant']==1]\n",
    "negative_samples = df[df['malignant']==0].sample(positive_samples['malignant'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([positive_samples,negative_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_data['comment_text']), np.array(train_data['malignant'])\n",
    "X_test, y_test = np.array(test_data['comment_text']), np.array(test_data['malignant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data by removing stopwords, links, html tags and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash_tokens = list(STOP_WORDS) + list(string.punctuation) + list(\" \")\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    if isinstance(X,str):\n",
    "        text = re.sub(r'<.*?>', '', X)\n",
    "        text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "        text = html.unescape(text)\n",
    "        text = re.sub(r'\\n|\\t|\\r', ' ', text)\n",
    "        text = text.strip()\n",
    "        tokens = nlp(text)\n",
    "        return [str(word).lower() for word in tokens if str(word).lower() not in trash_tokens]\n",
    "    \n",
    "    tmp = []\n",
    "    for i in range(X.shape[0]):\n",
    "        text = re.sub(r'<.*?>', '', X[i])\n",
    "        text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "        text = html.unescape(text)\n",
    "        text = re.sub(r'\\n|\\t|\\r', ' ', text)\n",
    "        text = text.strip()\n",
    "        tokens = nlp(text)\n",
    "        tmp.append([str(word).lower() for word in tokens if str(word).lower() not in trash_tokens])\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_X_train = preprocess_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency(X,Y):\n",
    "    word_dict = {}\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        text = X[i]\n",
    "        label = Y[i]\n",
    "\n",
    "        for word in text:\n",
    "            if word not in word_dict:\n",
    "                word_dict[word] = {'toxic':1,'normal':1}\n",
    "\n",
    "            if label == 1:\n",
    "                word_dict[word]['toxic'] += 1\n",
    "            else:\n",
    "                word_dict[word]['normal'] += 1\n",
    "\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = get_word_frequency(filtered_X_train, y_train)\n",
    "class_frequency = {'toxic':sum(y_train==1), 'normal':sum(y_train==0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_word_given_class(word,label,word_freq,class_freq):\n",
    "    prob_word = word_freq[word][label] / class_freq[label]\n",
    "    \n",
    "    return prob_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_sentence_given_class(sentence,label,word_freq,class_freq):\n",
    "    prob_sentence = 1\n",
    "    for word in sentence:\n",
    "        if word in word_freq.keys():\n",
    "            prob_sentence *= prob_word_given_class(word,label,word_freq,class_freq)\n",
    "    \n",
    "    return prob_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(X,word_freq,class_freq,return_likelihoods=False):\n",
    "    prob_toxic = class_frequency['toxic'] / (class_frequency['toxic'] + class_frequency['normal'])\n",
    "    prob_normal = class_frequency['normal'] / (class_frequency['toxic'] + class_frequency['normal'])\n",
    "    prob_sentence_given_toxic = prob_sentence_given_class(X,'toxic',word_freq,class_freq)\n",
    "    prob_sentence_given_normal = prob_sentence_given_class(X,'normal',word_freq,class_freq)\n",
    "\n",
    "    toxic_likelihood = prob_toxic * prob_sentence_given_toxic\n",
    "    normal_likelihood = prob_normal * prob_sentence_given_normal\n",
    "\n",
    "    if return_likelihoods:\n",
    "        return(toxic_likelihood, normal_likelihood)\n",
    "\n",
    "    if toxic_likelihood >= normal_likelihood:\n",
    "        return 1\n",
    "    elif normal_likelihood > toxic_likelihood:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    y_pred.append(naive_bayes_classifier(preprocess_data(X_test[i]),word_freq,class_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    true_positive = sum((y_true & y_pred) == 1)\n",
    "    true_negative = sum((y_true & y_pred) == 0)\n",
    "    false_negative = sum((y_true == 1) & (y_pred == 0))\n",
    "    false_positive = sum((y_true == 0) & (y_pred == 1))\n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return {\n",
    "        'accuracy' : accuracy,\n",
    "        'precision' : precision,\n",
    "        'recall' : recall,\n",
    "        'f1' : f1\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8641242937853107,\n",
       " 'precision': 0.9063214013709063,\n",
       " 'recall': 0.7687338501291989,\n",
       " 'f1': 0.8318769660957708}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob_sentence_given_class(sentence,label,word_freq,class_freq):\n",
    "    log_prob_sentence = 0\n",
    "    for word in sentence:\n",
    "        if word in word_freq.keys():\n",
    "            log_prob_sentence += np.log(prob_word_given_class(word,label,word_freq,class_freq))\n",
    "    \n",
    "    return log_prob_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_naive_bayes_classifier(X,word_freq,class_freq,return_likelihoods=False):\n",
    "    prob_toxic = class_frequency['toxic'] / (class_frequency['toxic'] + class_frequency['normal'])\n",
    "    prob_normal = class_frequency['normal'] / (class_frequency['toxic'] + class_frequency['normal'])\n",
    "    log_prob_sentence_given_toxic = log_prob_sentence_given_class(X,'toxic',word_freq,class_freq)\n",
    "    log_prob_sentence_given_normal = log_prob_sentence_given_class(X,'normal',word_freq,class_freq)\n",
    "\n",
    "    log_toxic_likelihood = np.log(prob_toxic) + log_prob_sentence_given_toxic\n",
    "    log_normal_likelihood = np.log(prob_normal) + log_prob_sentence_given_normal\n",
    "\n",
    "    if return_likelihoods:\n",
    "        return(log_toxic_likelihood, log_normal_likelihood)\n",
    "\n",
    "    if log_toxic_likelihood >= log_normal_likelihood:\n",
    "        return 1\n",
    "    elif log_normal_likelihood > log_toxic_likelihood:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = []\n",
    "for i in range(len(X_test)):\n",
    "    y_pred_log.append(log_naive_bayes_classifier(preprocess_data(X_test[i]),word_freq,class_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8706418101608083,\n",
       " 'precision': 0.9313609467455621,\n",
       " 'recall': 0.7625968992248062,\n",
       " 'f1': 0.838572189664358}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(y_test, y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
